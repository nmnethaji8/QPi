# QPi
GPU-accelerated solver for the Max Cut Problem in graphs
Use nvc++ compiler from nvidia hpc-sdk and curand library for random number generation
t1 = CPU time taken(seconds) in the published paper
t2 = GPU time taken(seconds) achieved
Bc1 = Best known cut in the paper
Bc2 = Best known cut calculated on GPU

Graph	Vertices Edges	Torus	t1	t2     speedup1	speedup2 Bc1	Bc2
G13	800	1600	yes	0.17	0.074	1.5	2.2973	580	824
G34	2000	4000	yes	0.29	0.16	2.6	1.8125	1372	2034
G19	800	4661	no	0.39	0.072	2.3	5.4167	903	2322
G21	800	4667	no	0.39	0.073	2.3	5.3425	931	2311
G20	800	4672	no	0.39	0.073	2.6	5.3425	941	2328
G18	800	4694	no	0.39	0.075	2.5	5.2	988	2375
G51	1000	5909	no	0.41	0.088	2.3	4.6591	3846	3306
G53	1000	5914	no	0.41	0.09	2.1	4.5556	3846	3330
G54	1000	5916	no	0.41	0.09	2	4.5556	3846	3354
G50	3000	6000	yes	0.49	0.235	3.2	2.0851	5880	4010
G47	1000	9990	no	0.64	0.092	4.3	6.9565	6656	5628
G40	2000	11766	no	0.81	0.174	3.4	4.6552	2387	5885
G39	2000	11778	no	0.76	0.174	3.7	4.3678	2395	6016
G42	2000	11779	no	0.76	0.168	2.9	4.5238	2469	5887
G41	2000	11785	no	0.76	0.172	3.1	4.4186	2398	5934
